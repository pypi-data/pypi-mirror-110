{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rank</th>\n",
       "      <th>count</th>\n",
       "      <th>prop100k</th>\n",
       "      <th>cum_prop100k</th>\n",
       "      <th>pctwhite</th>\n",
       "      <th>pctblack</th>\n",
       "      <th>pctapi</th>\n",
       "      <th>pctaian</th>\n",
       "      <th>pct2prace</th>\n",
       "      <th>pcthispanic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMITH</td>\n",
       "      <td>1</td>\n",
       "      <td>2442977</td>\n",
       "      <td>828.19</td>\n",
       "      <td>828.19</td>\n",
       "      <td>70.9</td>\n",
       "      <td>23.11</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.19</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOHNSON</td>\n",
       "      <td>2</td>\n",
       "      <td>1932812</td>\n",
       "      <td>655.24</td>\n",
       "      <td>1483.42</td>\n",
       "      <td>58.97</td>\n",
       "      <td>34.63</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WILLIAMS</td>\n",
       "      <td>3</td>\n",
       "      <td>1625252</td>\n",
       "      <td>550.97</td>\n",
       "      <td>2034.39</td>\n",
       "      <td>45.75</td>\n",
       "      <td>47.68</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.82</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BROWN</td>\n",
       "      <td>4</td>\n",
       "      <td>1437026</td>\n",
       "      <td>487.16</td>\n",
       "      <td>2521.56</td>\n",
       "      <td>57.95</td>\n",
       "      <td>35.6</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.87</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JONES</td>\n",
       "      <td>5</td>\n",
       "      <td>1425470</td>\n",
       "      <td>483.24</td>\n",
       "      <td>3004.80</td>\n",
       "      <td>55.19</td>\n",
       "      <td>38.48</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1</td>\n",
       "      <td>2.61</td>\n",
       "      <td>2.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162249</th>\n",
       "      <td>DIETZMANN</td>\n",
       "      <td>160975</td>\n",
       "      <td>100</td>\n",
       "      <td>0.03</td>\n",
       "      <td>90062.93</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162250</th>\n",
       "      <td>DOKAS</td>\n",
       "      <td>160975</td>\n",
       "      <td>100</td>\n",
       "      <td>0.03</td>\n",
       "      <td>90062.96</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162251</th>\n",
       "      <td>DONLEA</td>\n",
       "      <td>160975</td>\n",
       "      <td>100</td>\n",
       "      <td>0.03</td>\n",
       "      <td>90062.99</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162252</th>\n",
       "      <td>DORIOTT</td>\n",
       "      <td>160975</td>\n",
       "      <td>100</td>\n",
       "      <td>0.03</td>\n",
       "      <td>90063.03</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162253</th>\n",
       "      <td>ALL OTHER NAMES</td>\n",
       "      <td>0</td>\n",
       "      <td>29312001</td>\n",
       "      <td>9936.97</td>\n",
       "      <td>9936.97</td>\n",
       "      <td>66.65</td>\n",
       "      <td>8.53</td>\n",
       "      <td>7.97</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2.32</td>\n",
       "      <td>13.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162253 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name    rank     count  prop100k  cum_prop100k pctwhite  \\\n",
       "0                 SMITH       1   2442977    828.19        828.19     70.9   \n",
       "1               JOHNSON       2   1932812    655.24       1483.42    58.97   \n",
       "2              WILLIAMS       3   1625252    550.97       2034.39    45.75   \n",
       "3                 BROWN       4   1437026    487.16       2521.56    57.95   \n",
       "4                 JONES       5   1425470    483.24       3004.80    55.19   \n",
       "...                 ...     ...       ...       ...           ...      ...   \n",
       "162249        DIETZMANN  160975       100      0.03      90062.93       96   \n",
       "162250            DOKAS  160975       100      0.03      90062.96       94   \n",
       "162251           DONLEA  160975       100      0.03      90062.99       94   \n",
       "162252          DORIOTT  160975       100      0.03      90063.03       89   \n",
       "162253  ALL OTHER NAMES       0  29312001   9936.97       9936.97    66.65   \n",
       "\n",
       "       pctblack pctapi pctaian pct2prace pcthispanic  \n",
       "0         23.11    0.5    0.89      2.19         2.4  \n",
       "1         34.63   0.54    0.94      2.56        2.36  \n",
       "2         47.68   0.46    0.82      2.81        2.49  \n",
       "3          35.6   0.51    0.87      2.55        2.52  \n",
       "4         38.48   0.44       1      2.61        2.29  \n",
       "...         ...    ...     ...       ...         ...  \n",
       "162249        0      0       0         0           0  \n",
       "162250        0      0       0         0           0  \n",
       "162251        0      0       0         0           6  \n",
       "162252        0      0       0         5           0  \n",
       "162253     8.53   7.97    0.86      2.32       13.67  \n",
       "\n",
       "[162253 rows x 11 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "NGRAMS = 2\n",
    "EPOCHS = 5\n",
    "#YEAR = '2000'\n",
    "YEAR = '2010'\n",
    "\n",
    "df = pd.read_csv('../../data/census/census_%s.csv' % YEAR)\n",
    "df.dropna(subset=['name'], inplace=True)\n",
    "df.replace('(S)', 0, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling with weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = df.sample(1000000, weights=df['count'], replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign race by pertcentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rank</th>\n",
       "      <th>count</th>\n",
       "      <th>prop100k</th>\n",
       "      <th>cum_prop100k</th>\n",
       "      <th>pctwhite</th>\n",
       "      <th>pctblack</th>\n",
       "      <th>pctapi</th>\n",
       "      <th>pctaian</th>\n",
       "      <th>pct2prace</th>\n",
       "      <th>pcthispanic</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JONES</td>\n",
       "      <td>5</td>\n",
       "      <td>1425470</td>\n",
       "      <td>483.24</td>\n",
       "      <td>3004.80</td>\n",
       "      <td>55.19</td>\n",
       "      <td>38.48</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1</td>\n",
       "      <td>2.61</td>\n",
       "      <td>2.29</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144925</th>\n",
       "      <td>SCHURGER</td>\n",
       "      <td>144141</td>\n",
       "      <td>115</td>\n",
       "      <td>0.04</td>\n",
       "      <td>89435.56</td>\n",
       "      <td>98.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>PAYNE</td>\n",
       "      <td>195</td>\n",
       "      <td>142601</td>\n",
       "      <td>48.34</td>\n",
       "      <td>23037.13</td>\n",
       "      <td>71.55</td>\n",
       "      <td>22.63</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>2.37</td>\n",
       "      <td>2.42</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>CHEN</td>\n",
       "      <td>150</td>\n",
       "      <td>169580</td>\n",
       "      <td>57.49</td>\n",
       "      <td>20664.71</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>96.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.52</td>\n",
       "      <td>api</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>FLORES</td>\n",
       "      <td>40</td>\n",
       "      <td>433969</td>\n",
       "      <td>147.12</td>\n",
       "      <td>11243.84</td>\n",
       "      <td>4.87</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.36</td>\n",
       "      <td>91.94</td>\n",
       "      <td>hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10840</th>\n",
       "      <td>PEIFFER</td>\n",
       "      <td>10837</td>\n",
       "      <td>2938</td>\n",
       "      <td>1.00</td>\n",
       "      <td>69235.34</td>\n",
       "      <td>95.98</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>BARROW</td>\n",
       "      <td>2159</td>\n",
       "      <td>16801</td>\n",
       "      <td>5.70</td>\n",
       "      <td>50250.23</td>\n",
       "      <td>66.63</td>\n",
       "      <td>26.67</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.14</td>\n",
       "      <td>3.49</td>\n",
       "      <td>hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>MCRAE</td>\n",
       "      <td>1987</td>\n",
       "      <td>18156</td>\n",
       "      <td>6.16</td>\n",
       "      <td>49239.38</td>\n",
       "      <td>52.7</td>\n",
       "      <td>41.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.58</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>THOMPSON</td>\n",
       "      <td>23</td>\n",
       "      <td>664644</td>\n",
       "      <td>225.32</td>\n",
       "      <td>8302.08</td>\n",
       "      <td>69.78</td>\n",
       "      <td>23.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2.37</td>\n",
       "      <td>2.49</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162253</th>\n",
       "      <td>ALL OTHER NAMES</td>\n",
       "      <td>0</td>\n",
       "      <td>29312001</td>\n",
       "      <td>9936.97</td>\n",
       "      <td>9936.97</td>\n",
       "      <td>66.65</td>\n",
       "      <td>8.53</td>\n",
       "      <td>7.97</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2.32</td>\n",
       "      <td>13.67</td>\n",
       "      <td>api</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name    rank     count  prop100k  cum_prop100k pctwhite  \\\n",
       "4                 JONES       5   1425470    483.24       3004.80    55.19   \n",
       "144925         SCHURGER  144141       115      0.04      89435.56    98.26   \n",
       "194               PAYNE     195    142601     48.34      23037.13    71.55   \n",
       "149                CHEN     150    169580     57.49      20664.71      1.4   \n",
       "39               FLORES      40    433969    147.12      11243.84     4.87   \n",
       "...                 ...     ...       ...       ...           ...      ...   \n",
       "10840           PEIFFER   10837      2938      1.00      69235.34    95.98   \n",
       "2158             BARROW    2159     16801      5.70      50250.23    66.63   \n",
       "1987              MCRAE    1987     18156      6.16      49239.38     52.7   \n",
       "22             THOMPSON      23    664644    225.32       8302.08    69.78   \n",
       "162253  ALL OTHER NAMES       0  29312001   9936.97       9936.97    66.65   \n",
       "\n",
       "       pctblack pctapi pctaian pct2prace pcthispanic      race  \n",
       "4         38.48   0.44       1      2.61        2.29     white  \n",
       "144925        0      0       0         0           0     white  \n",
       "194       22.63   0.45    0.58      2.37        2.42     white  \n",
       "149         0.3  96.12    0.02      1.64        0.52       api  \n",
       "39         0.42   2.08    0.34      0.36       91.94  hispanic  \n",
       "...         ...    ...     ...       ...         ...       ...  \n",
       "10840      0.44   0.54    0.34      1.09         1.6     white  \n",
       "2158      26.67   0.51    0.55      2.14        3.49  hispanic  \n",
       "1987      41.41   0.41    0.44      2.46        2.58     white  \n",
       "22        23.57   0.57    1.22      2.37        2.49     white  \n",
       "162253     8.53   7.97    0.86      2.32       13.67       api  \n",
       "\n",
       "[1000000 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.random import choice\n",
    "\n",
    "races = ['white', 'black', 'api', 'hispanic']\n",
    "\n",
    "def to_race(c):\n",
    "    w = np.array(c).astype(float)\n",
    "    if w.sum() == 0:\n",
    "        return 'white'\n",
    "    probs = w/w.sum()\n",
    "    return choice(races, p=probs)\n",
    "\n",
    "sdf['race'] = sdf[['pctwhite', 'pctblack', 'pctapi', 'pcthispanic']].apply(lambda c: to_race(c), axis=1)\n",
    "sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the correctness of race assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rank</th>\n",
       "      <th>count</th>\n",
       "      <th>prop100k</th>\n",
       "      <th>cum_prop100k</th>\n",
       "      <th>pctwhite</th>\n",
       "      <th>pctblack</th>\n",
       "      <th>pctapi</th>\n",
       "      <th>pctaian</th>\n",
       "      <th>pct2prace</th>\n",
       "      <th>pcthispanic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMITH</td>\n",
       "      <td>1</td>\n",
       "      <td>2442977</td>\n",
       "      <td>828.19</td>\n",
       "      <td>828.19</td>\n",
       "      <td>70.9</td>\n",
       "      <td>23.11</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.19</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  rank    count  prop100k  cum_prop100k pctwhite pctblack pctapi  \\\n",
       "0  SMITH     1  2442977    828.19        828.19     70.9    23.11    0.5   \n",
       "\n",
       "  pctaian pct2prace pcthispanic  \n",
       "0    0.89      2.19         2.4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.name == 'SMITH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>api</th>\n",
       "      <td>0.534564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>24.322683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hispanic</th>\n",
       "      <td>2.636375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>72.506378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name\n",
       "race               \n",
       "api        0.534564\n",
       "black     24.322683\n",
       "hispanic   2.636375\n",
       "white     72.506378"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdf = sdf[sdf.name=='SMITH'].groupby(['race']).agg({'name': 'count'})\n",
    "xdf * 100 / xdf.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_last</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>api</th>\n",
       "      <td>50010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>124213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hispanic</th>\n",
       "      <td>165099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>660678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name_last\n",
       "race               \n",
       "api           50010\n",
       "black        124213\n",
       "hispanic     165099\n",
       "white        660678"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additional features\n",
    "sdf['name_last'] = sdf.name.str.title()\n",
    "sdf.groupby('race').agg({'name_last': 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "973"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only last name in Census data\n",
    "sdf['name_last_name_first'] = sdf['name_last']\n",
    "\n",
    "# build n-gram list\n",
    "vect = CountVectorizer(analyzer='char', max_df=0.3, min_df=3, ngram_range=(NGRAMS, NGRAMS), lowercase=False) \n",
    "#vect = CountVectorizer(analyzer='char', ngram_range=(2, 2), lowercase=False) \n",
    "a = vect.fit_transform(sdf.name_last_name_first)\n",
    "vocab = vect.vocabulary_\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_vocab = sorted(vocab.items(), key=operator.itemgetter(1))\n",
    "cols = list(map(operator.itemgetter(0), sorted_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>O</th>\n",
       "      <th>Aa</th>\n",
       "      <th>Ab</th>\n",
       "      <th>Ac</th>\n",
       "      <th>Ad</th>\n",
       "      <th>Ae</th>\n",
       "      <th>Af</th>\n",
       "      <th>Ag</th>\n",
       "      <th>Ah</th>\n",
       "      <th>...</th>\n",
       "      <th>zp</th>\n",
       "      <th>zq</th>\n",
       "      <th>zr</th>\n",
       "      <th>zs</th>\n",
       "      <th>zt</th>\n",
       "      <th>zu</th>\n",
       "      <th>zv</th>\n",
       "      <th>zw</th>\n",
       "      <th>zy</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows Ã— 973 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         N   O  Aa  Ab  Ac  Ad  Ae  Af  Ag  Ah  ...  zp  zq  zr  zs  zt  zu  \\\n",
       "0        0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "1        0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "2        0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "3        0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "4        0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "...     ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..   \n",
       "999995   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "999996   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "999997   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "999998   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "999999   1   1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "\n",
       "        zv  zw  zy  zz  \n",
       "0        0   0   0   0  \n",
       "1        0   0   0   0  \n",
       "2        0   0   0   0  \n",
       "3        0   0   0   0  \n",
       "4        0   0   0   0  \n",
       "...     ..  ..  ..  ..  \n",
       "999995   0   0   0   0  \n",
       "999996   0   0   0   0  \n",
       "999997   0   0   0   0  \n",
       "999998   0   0   0   0  \n",
       "999999   0   0   0   0  \n",
       "\n",
       "[1000000 rows x 973 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df = pd.DataFrame(a.todense(), columns=cols)\n",
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       973.000000\n",
       "mean       6347.018499\n",
       "std       18212.901816\n",
       "min           3.000000\n",
       "25%          80.000000\n",
       "50%         833.000000\n",
       "75%        5050.000000\n",
       "max      253964.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df.sum().sort_values(ascending=False).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "er    253964\n",
       "ll    174869\n",
       "es    144194\n",
       "am    131946\n",
       "he    124439\n",
       "       ...  \n",
       "Uj         3\n",
       "Uf         3\n",
       "qe         3\n",
       "bj         3\n",
       "jz         3\n",
       "Length: 973, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 20)\n",
    "count_df.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words = 973\n"
     ]
    }
   ],
   "source": [
    "# sort n-gram by freq (highest -> lowest)\n",
    "words = []\n",
    "for b in vocab:\n",
    "    c = vocab[b]\n",
    "    #print(b, c, a[:, c].sum())\n",
    "    words.append((a[:, c].sum(), b))\n",
    "    #break\n",
    "words = sorted(words, reverse=True)\n",
    "words_list = [w[1] for w in words]\n",
    "num_words = len(words_list)\n",
    "print(\"num_words = %d\" % num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max feature len = 14, Avg. feature len = 6\n"
     ]
    }
   ],
   "source": [
    "def find_ngrams(text, n):\n",
    "    a = zip(*[text[i:] for i in range(n)])\n",
    "    wi = []\n",
    "    for i in a:\n",
    "        w = ''.join(i)\n",
    "        try:\n",
    "            idx = words_list.index(w)\n",
    "        except:\n",
    "            idx = 0\n",
    "        wi.append(idx)\n",
    "    return wi\n",
    "\n",
    "# build X from index of n-gram sequence\n",
    "X = np.array(sdf.name_last_name_first.apply(lambda c: find_ngrams(c, NGRAMS)))\n",
    "\n",
    "# check max/avg feature\n",
    "X_len = []\n",
    "for x in X:\n",
    "    X_len.append(len(x))\n",
    "\n",
    "max_feature_len = max(X_len)\n",
    "avg_feature_len = int(np.mean(X_len))\n",
    "\n",
    "print(\"Max feature len = %d, Avg. feature len = %d\" % (max_feature_len, avg_feature_len))\n",
    "y = np.array(sdf.race.astype('category').cat.codes)\n",
    "\n",
    "# Split train and test dataset\n",
    "X_train,  X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a LSTM model\n",
    "\n",
    "ref: http://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800000 train sequences\n",
      "200000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "X_train shape: (800000, 20)\n",
      "X_test shape: (200000, 20)\n",
      "4 classes\n",
      "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
      "y_train shape: (800000, 4)\n",
      "y_test shape: (200000, 4)\n"
     ]
    }
   ],
   "source": [
    "'''The dataset is actually too small for LSTM to be of any advantage\n",
    "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
    "Notes:\n",
    "\n",
    "- RNNs are tricky. Choice of batch size is important,\n",
    "choice of loss and optimizer is critical, etc.\n",
    "Some configurations won't converge.\n",
    "\n",
    "- LSTM loss decrease patterns during training can be quite different\n",
    "from what you see with CNNs/MLPs/etc.\n",
    "'''\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.models import load_model\n",
    "\n",
    "max_features = num_words # 20000\n",
    "feature_len = 20 # avg_feature_len # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=feature_len)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=feature_len)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "print(num_classes, 'classes')\n",
    "\n",
    "print('Convert class vector to binary class matrix '\n",
    "      '(for use with categorical_crossentropy)')\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 32)            31136     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               82432     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 114,084\n",
      "Trainable params: 114,084\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, 32, input_length=feature_len))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/5\n",
      "22500/22500 - 676s - loss: 0.6520 - accuracy: 0.7770 - val_loss: 0.6263 - val_accuracy: 0.7855\n",
      "Epoch 2/5\n",
      "22500/22500 - 1052s - loss: 0.6138 - accuracy: 0.7895 - val_loss: 0.6070 - val_accuracy: 0.7925\n",
      "Epoch 3/5\n",
      "22500/22500 - 1141s - loss: 0.6004 - accuracy: 0.7938 - val_loss: 0.5967 - val_accuracy: 0.7953\n",
      "Epoch 4/5\n",
      "22500/22500 - 967s - loss: 0.5927 - accuracy: 0.7959 - val_loss: 0.5893 - val_accuracy: 0.7968\n",
      "Epoch 5/5\n",
      "22500/22500 - 622s - loss: 0.5878 - accuracy: 0.7973 - val_loss: 0.5864 - val_accuracy: 0.7972\n",
      "6250/6250 - 18s - loss: 0.5835 - accuracy: 0.7986\n",
      "Test score: 0.5835372805595398\n",
      "Test accuracy: 0.7986400127410889\n"
     ]
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=EPOCHS,\n",
    "          validation_split=0.1, verbose=2)\n",
    "score, acc = model.evaluate(X_test, y_test,\n",
    "                            batch_size=batch_size, verbose=2)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/madhusanjeevi/Desktop/GauravFreelanceing/env/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 - 18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/madhusanjeevi/Desktop/GauravFreelanceing/env/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 - 19s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         api       0.84      0.56      0.67     10002\n",
      "       black       0.53      0.07      0.13     24843\n",
      "    hispanic       0.87      0.76      0.81     33020\n",
      "       white       0.79      0.96      0.87    132135\n",
      "\n",
      "    accuracy                           0.80    200000\n",
      "   macro avg       0.76      0.59      0.62    200000\n",
      "weighted avg       0.77      0.80      0.76    200000\n",
      "\n",
      "[[  5633     30    797   3542]\n",
      " [   246   1764    257  22576]\n",
      " [   166    110  25153   7591]\n",
      " [   687   1442   2828 127178]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test, verbose=2)\n",
    "p = model.predict_proba(X_test, verbose=2) # to predict probability\n",
    "target_names = list(sdf.race.astype('category').cat.categories)\n",
    "print(classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(y_test, axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/census/lstm/census%s_ln_lstm.h5' % YEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.DataFrame(words_list, columns=['vocab'])\n",
    "words_df.to_csv('./models/census/lstm/census%s_ln_vocab.csv' % YEAR, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/madhusanjeevi/Desktop/GauravFreelanceing/env/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 - 72s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         api       0.84      0.57      0.68     40008\n",
      "       black       0.55      0.07      0.13     99370\n",
      "    hispanic       0.87      0.77      0.82    132079\n",
      "       white       0.79      0.96      0.87    528543\n",
      "\n",
      "    accuracy                           0.80    800000\n",
      "   macro avg       0.76      0.59      0.62    800000\n",
      "weighted avg       0.78      0.80      0.76    800000\n",
      "\n",
      "[[ 22795    132   3162  13919]\n",
      " [   944   7196    981  90249]\n",
      " [   628    325 101179  29947]\n",
      " [  2678   5407  10536 509922]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_train, verbose=2)\n",
    "target_names = list(sdf.race.astype('category').cat.categories)\n",
    "print(classification_report(np.argmax(y_train, axis=1), y_pred, target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(y_train, axis=1), y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
