{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/voters_csv/\"\n",
    "columns = [\"CountyCode\",\"VoterID\",\"LastName\",\"FirstName\",\"MiddleName\",\"Race\",\"DOB\"]\n",
    "files = os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALA_20170207.csv',\n",
       " 'BAK_20170207.csv',\n",
       " 'BAY_20170207.csv',\n",
       " 'BRA_20170207.csv',\n",
       " 'BRE_20170207.csv',\n",
       " 'BRO_20170207.csv',\n",
       " 'CAL_20170207.csv',\n",
       " 'CHA_20170207.csv',\n",
       " 'CIT_20170207.csv',\n",
       " 'CLA_20170207.csv',\n",
       " 'CLL_20170207.csv',\n",
       " 'CLM_20170207.csv',\n",
       " 'DAD_20170207.csv',\n",
       " 'DES_20170207.csv',\n",
       " 'DIX_20170207.csv',\n",
       " 'DUV_20170207.csv',\n",
       " 'ESC_20170207.csv',\n",
       " 'FLA_20170207.csv',\n",
       " 'FRA_20170207.csv',\n",
       " 'GAD_20170207.csv',\n",
       " 'GIL_20170207.csv',\n",
       " 'GLA_20170207.csv',\n",
       " 'GUL_20170207.csv',\n",
       " 'HAM_20170207.csv',\n",
       " 'HAR_20170207.csv',\n",
       " 'HEN_20170207.csv',\n",
       " 'HER_20170207.csv',\n",
       " 'HIG_20170207.csv',\n",
       " 'HIL_20170207.csv',\n",
       " 'HOL_20170207.csv',\n",
       " 'IND_20170207.csv',\n",
       " 'JAC_20170207.csv',\n",
       " 'JEF_20170207.csv',\n",
       " 'LAF_20170207.csv',\n",
       " 'LAK_20170207.csv',\n",
       " 'LEE_20170207.csv',\n",
       " 'LEO_20170207.csv',\n",
       " 'LEV_20170207.csv',\n",
       " 'LIB_20170207.csv',\n",
       " 'MAD_20170207.csv',\n",
       " 'MAN_20170207.csv',\n",
       " 'MON_20170207.csv',\n",
       " 'MRN_20170207.csv',\n",
       " 'MRT_20170207.csv',\n",
       " 'NAS_20170207.csv',\n",
       " 'OKA_20170207.csv',\n",
       " 'OKE_20170207.csv',\n",
       " 'ORA_20170207.csv',\n",
       " 'OSC_20170207.csv',\n",
       " 'PAL_20170207.csv',\n",
       " 'PAS_20170207.csv',\n",
       " 'PIN_20170207.csv',\n",
       " 'POL_20170207.csv',\n",
       " 'PUT_20170207.csv',\n",
       " 'SAN_20170207.csv',\n",
       " 'SAR_20170207.csv',\n",
       " 'SEM_20170207.csv',\n",
       " 'STJ_20170207.csv',\n",
       " 'STL_20170207.csv',\n",
       " 'SUM_20170207.csv',\n",
       " 'SUW_20170207.csv',\n",
       " 'TAY_20170207.csv',\n",
       " 'UNI_20170207.csv',\n",
       " 'VOL_20170207.csv',\n",
       " 'WAK_20170207.csv',\n",
       " 'WAL_20170207.csv',\n",
       " 'WAS_20170207.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tryint(s):\n",
    "    try:\n",
    "        return int(s)\n",
    "    except ValueError:\n",
    "        return s\n",
    "\n",
    "def alphanum_key(s):\n",
    "    return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n",
    "\n",
    "def sort_nicely(l):\n",
    "    l.sort(key=alphanum_key)\n",
    "\n",
    "sort_nicely(files)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for file in files:\n",
    "    temp_df = pd.read_csv(data_path+file)\n",
    "    df_list = [df, temp_df]\n",
    "    df = pd.concat(df_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountyCode</th>\n",
       "      <th>VoterID</th>\n",
       "      <th>LastName</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>MiddleName</th>\n",
       "      <th>Race</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALA</td>\n",
       "      <td>102947246</td>\n",
       "      <td>Walker</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "      <td>12/28/1961</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALA</td>\n",
       "      <td>122030263</td>\n",
       "      <td>Palmer</td>\n",
       "      <td>Alton</td>\n",
       "      <td>Douglas</td>\n",
       "      <td>5</td>\n",
       "      <td>03/14/1943</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALA</td>\n",
       "      <td>101628984</td>\n",
       "      <td>Mc Cleod</td>\n",
       "      <td>Alicia</td>\n",
       "      <td>D</td>\n",
       "      <td>3</td>\n",
       "      <td>08/20/1966</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALA</td>\n",
       "      <td>101669113</td>\n",
       "      <td>Scarborough</td>\n",
       "      <td>Dale</td>\n",
       "      <td>Fredrick</td>\n",
       "      <td>5</td>\n",
       "      <td>03/07/1951</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALA</td>\n",
       "      <td>101745548</td>\n",
       "      <td>Walker</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>Ray</td>\n",
       "      <td>5</td>\n",
       "      <td>06/22/1955</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15804</th>\n",
       "      <td>WAS</td>\n",
       "      <td>100698798</td>\n",
       "      <td>Walters</td>\n",
       "      <td>William</td>\n",
       "      <td>Walter</td>\n",
       "      <td>5</td>\n",
       "      <td>07/25/1946</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15805</th>\n",
       "      <td>WAS</td>\n",
       "      <td>104711661</td>\n",
       "      <td>Sawyer</td>\n",
       "      <td>Matthew</td>\n",
       "      <td>Lee</td>\n",
       "      <td>5</td>\n",
       "      <td>07/01/1984</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15806</th>\n",
       "      <td>WAS</td>\n",
       "      <td>100726687</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>Janine</td>\n",
       "      <td>O'Riska</td>\n",
       "      <td>5</td>\n",
       "      <td>03/02/1987</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15807</th>\n",
       "      <td>WAS</td>\n",
       "      <td>122496331</td>\n",
       "      <td>Campbell</td>\n",
       "      <td>Angel</td>\n",
       "      <td>Rose</td>\n",
       "      <td>7</td>\n",
       "      <td>08/14/1998</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15808</th>\n",
       "      <td>WAS</td>\n",
       "      <td>122291178</td>\n",
       "      <td>Bruner</td>\n",
       "      <td>Jeb</td>\n",
       "      <td>Ellis</td>\n",
       "      <td>5</td>\n",
       "      <td>04/10/1997</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13099661 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CountyCode    VoterID     LastName  FirstName MiddleName Race  \\\n",
       "0            ALA  102947246       Walker  Elizabeth          A    5   \n",
       "1            ALA  122030263       Palmer      Alton    Douglas    5   \n",
       "2            ALA  101628984     Mc Cleod     Alicia          D    3   \n",
       "3            ALA  101669113  Scarborough       Dale   Fredrick    5   \n",
       "4            ALA  101745548       Walker     Daniel        Ray    5   \n",
       "...          ...        ...          ...        ...        ...  ...   \n",
       "15804        WAS  100698798      Walters    William     Walter    5   \n",
       "15805        WAS  104711661       Sawyer    Matthew        Lee    5   \n",
       "15806        WAS  100726687       Thomas     Janine    O'Riska    5   \n",
       "15807        WAS  122496331     Campbell      Angel       Rose    7   \n",
       "15808        WAS  122291178       Bruner        Jeb      Ellis    5   \n",
       "\n",
       "              DOB  Unnamed: 0  \n",
       "0      12/28/1961         0.0  \n",
       "1      03/14/1943         0.0  \n",
       "2      08/20/1966         0.0  \n",
       "3      03/07/1951         0.0  \n",
       "4      06/22/1955         0.0  \n",
       "...           ...         ...  \n",
       "15804  07/25/1946         0.0  \n",
       "15805  07/01/1984         0.0  \n",
       "15806  03/02/1987         0.0  \n",
       "15807  08/14/1998         0.0  \n",
       "15808  04/10/1997         0.0  \n",
       "\n",
       "[13099661 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-455d8b9a0eb4>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Race'] = df['Race'].replace([9],8)\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df['Race'] = df['Race'].replace([9],8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    7648545\n",
       "3    1396642\n",
       "4    1239698\n",
       "8     200862\n",
       "2     173564\n",
       "6     143900\n",
       "7      73845\n",
       "1      38359\n",
       "Name: Race, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountyCode</th>\n",
       "      <th>VoterID</th>\n",
       "      <th>LastName</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>MiddleName</th>\n",
       "      <th>Race</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALA</td>\n",
       "      <td>102947246</td>\n",
       "      <td>Walker</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "      <td>12/28/1961</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALA</td>\n",
       "      <td>122030263</td>\n",
       "      <td>Palmer</td>\n",
       "      <td>Alton</td>\n",
       "      <td>Douglas</td>\n",
       "      <td>5</td>\n",
       "      <td>03/14/1943</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALA</td>\n",
       "      <td>101628984</td>\n",
       "      <td>Mc Cleod</td>\n",
       "      <td>Alicia</td>\n",
       "      <td>D</td>\n",
       "      <td>3</td>\n",
       "      <td>08/20/1966</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALA</td>\n",
       "      <td>101669113</td>\n",
       "      <td>Scarborough</td>\n",
       "      <td>Dale</td>\n",
       "      <td>Fredrick</td>\n",
       "      <td>5</td>\n",
       "      <td>03/07/1951</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALA</td>\n",
       "      <td>101745548</td>\n",
       "      <td>Walker</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>Ray</td>\n",
       "      <td>5</td>\n",
       "      <td>06/22/1955</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15804</th>\n",
       "      <td>WAS</td>\n",
       "      <td>100698798</td>\n",
       "      <td>Walters</td>\n",
       "      <td>William</td>\n",
       "      <td>Walter</td>\n",
       "      <td>5</td>\n",
       "      <td>07/25/1946</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15805</th>\n",
       "      <td>WAS</td>\n",
       "      <td>104711661</td>\n",
       "      <td>Sawyer</td>\n",
       "      <td>Matthew</td>\n",
       "      <td>Lee</td>\n",
       "      <td>5</td>\n",
       "      <td>07/01/1984</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15806</th>\n",
       "      <td>WAS</td>\n",
       "      <td>100726687</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>Janine</td>\n",
       "      <td>O'Riska</td>\n",
       "      <td>5</td>\n",
       "      <td>03/02/1987</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15807</th>\n",
       "      <td>WAS</td>\n",
       "      <td>122496331</td>\n",
       "      <td>Campbell</td>\n",
       "      <td>Angel</td>\n",
       "      <td>Rose</td>\n",
       "      <td>7</td>\n",
       "      <td>08/14/1998</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15808</th>\n",
       "      <td>WAS</td>\n",
       "      <td>122291178</td>\n",
       "      <td>Bruner</td>\n",
       "      <td>Jeb</td>\n",
       "      <td>Ellis</td>\n",
       "      <td>5</td>\n",
       "      <td>04/10/1997</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10915415 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CountyCode    VoterID     LastName  FirstName MiddleName  Race  \\\n",
       "0            ALA  102947246       Walker  Elizabeth          A     5   \n",
       "1            ALA  122030263       Palmer      Alton    Douglas     5   \n",
       "2            ALA  101628984     Mc Cleod     Alicia          D     3   \n",
       "3            ALA  101669113  Scarborough       Dale   Fredrick     5   \n",
       "4            ALA  101745548       Walker     Daniel        Ray     5   \n",
       "...          ...        ...          ...        ...        ...   ...   \n",
       "15804        WAS  100698798      Walters    William     Walter     5   \n",
       "15805        WAS  104711661       Sawyer    Matthew        Lee     5   \n",
       "15806        WAS  100726687       Thomas     Janine    O'Riska     5   \n",
       "15807        WAS  122496331     Campbell      Angel       Rose     7   \n",
       "15808        WAS  122291178       Bruner        Jeb      Ellis     5   \n",
       "\n",
       "              DOB  Unnamed: 0  \n",
       "0      12/28/1961         0.0  \n",
       "1      03/14/1943         0.0  \n",
       "2      08/20/1966         0.0  \n",
       "3      03/07/1951         0.0  \n",
       "4      06/22/1955         0.0  \n",
       "...           ...         ...  \n",
       "15804  07/25/1946         0.0  \n",
       "15805  07/01/1984         0.0  \n",
       "15806  03/02/1987         0.0  \n",
       "15807  08/14/1998         0.0  \n",
       "15808  04/10/1997         0.0  \n",
       "\n",
       "[10915415 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df.copy()\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['Race'] = new_df['Race'].replace([1],10)\n",
    "new_df['Race'] = new_df['Race'].replace([2],1)\n",
    "new_df['Race'] = new_df['Race'].replace([3],2)\n",
    "new_df['Race'] = new_df['Race'].replace([4],3)\n",
    "new_df['Race'] = new_df['Race'].replace([5],4)\n",
    "new_df['Race'] = new_df['Race'].replace([6],10)\n",
    "new_df['Race'] = new_df['Race'].replace([7],10)\n",
    "new_df['Race'] = new_df['Race'].replace([8],10)\n",
    "new_df['Race'] = new_df['Race'].replace([10],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    7648545\n",
       "2    1396642\n",
       "3    1239698\n",
       "5     456966\n",
       "1     173564\n",
       "Name: Race, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.Race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for i in range(9):\n",
    "    temp_df = new_df.loc[new_df['Race'] == i]\n",
    "    temp_df = temp_df[:][:100000]\n",
    "    df_list = [final_df, temp_df]\n",
    "    final_df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    100000\n",
       "4    100000\n",
       "3    100000\n",
       "2    100000\n",
       "1    100000\n",
       "Name: Race, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.Race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountyCode</th>\n",
       "      <th>VoterID</th>\n",
       "      <th>LastName</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>MiddleName</th>\n",
       "      <th>Race</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ALA</td>\n",
       "      <td>102092701</td>\n",
       "      <td>Estores</td>\n",
       "      <td>David</td>\n",
       "      <td>Suarez</td>\n",
       "      <td>1</td>\n",
       "      <td>08/04/1960</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>ALA</td>\n",
       "      <td>102502801</td>\n",
       "      <td>Jarvinen</td>\n",
       "      <td>Vilma</td>\n",
       "      <td>J</td>\n",
       "      <td>1</td>\n",
       "      <td>02/12/1987</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>ALA</td>\n",
       "      <td>111784844</td>\n",
       "      <td>Hossain</td>\n",
       "      <td>Begum</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>07/31/1956</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>ALA</td>\n",
       "      <td>114347572</td>\n",
       "      <td>Tran</td>\n",
       "      <td>Cac</td>\n",
       "      <td>Van</td>\n",
       "      <td>1</td>\n",
       "      <td>10/28/1963</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>ALA</td>\n",
       "      <td>114274710</td>\n",
       "      <td>Haider</td>\n",
       "      <td>Mohammad</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>12/16/1987</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672964</th>\n",
       "      <td>DAD</td>\n",
       "      <td>109872648</td>\n",
       "      <td>Benjamin</td>\n",
       "      <td>Mary</td>\n",
       "      <td>T</td>\n",
       "      <td>5</td>\n",
       "      <td>09/06/1932</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672968</th>\n",
       "      <td>DAD</td>\n",
       "      <td>109722566</td>\n",
       "      <td>Aguilar</td>\n",
       "      <td>Martha</td>\n",
       "      <td>G</td>\n",
       "      <td>5</td>\n",
       "      <td>02/11/1958</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672973</th>\n",
       "      <td>DAD</td>\n",
       "      <td>109863102</td>\n",
       "      <td>Claudio</td>\n",
       "      <td>Luis</td>\n",
       "      <td>Yoel</td>\n",
       "      <td>5</td>\n",
       "      <td>06/06/1981</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672988</th>\n",
       "      <td>DAD</td>\n",
       "      <td>109964609</td>\n",
       "      <td>Roges</td>\n",
       "      <td>Pedro</td>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>05/12/1946</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672996</th>\n",
       "      <td>DAD</td>\n",
       "      <td>110131886</td>\n",
       "      <td>Tuttle</td>\n",
       "      <td>Katherine</td>\n",
       "      <td>R</td>\n",
       "      <td>5</td>\n",
       "      <td>09/28/1983</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CountyCode    VoterID  LastName  FirstName MiddleName Race         DOB  \\\n",
       "17            ALA  102092701   Estores      David     Suarez    1  08/04/1960   \n",
       "86            ALA  102502801  Jarvinen      Vilma          J    1  02/12/1987   \n",
       "142           ALA  111784844   Hossain      Begum          R    1  07/31/1956   \n",
       "208           ALA  114347572      Tran        Cac        Van    1  10/28/1963   \n",
       "248           ALA  114274710    Haider   Mohammad          L    1  12/16/1987   \n",
       "...           ...        ...       ...        ...        ...  ...         ...   \n",
       "672964        DAD  109872648  Benjamin       Mary          T    5  09/06/1932   \n",
       "672968        DAD  109722566   Aguilar     Martha          G    5  02/11/1958   \n",
       "672973        DAD  109863102   Claudio       Luis       Yoel    5  06/06/1981   \n",
       "672988        DAD  109964609     Roges      Pedro          P    5  05/12/1946   \n",
       "672996        DAD  110131886    Tuttle  Katherine          R    5  09/28/1983   \n",
       "\n",
       "        Unnamed: 0  \n",
       "17             0.0  \n",
       "86             0.0  \n",
       "142            0.0  \n",
       "208            0.0  \n",
       "248            0.0  \n",
       "...            ...  \n",
       "672964         0.0  \n",
       "672968         0.0  \n",
       "672973         0.0  \n",
       "672988         0.0  \n",
       "672996         0.0  \n",
       "\n",
       "[500000 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from matplotlib import pyplot\n",
    "from numpy import where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NGRAMS = 2\n",
    "vect = CountVectorizer(analyzer='char', max_df=0.3, min_df=3, ngram_range=(NGRAMS, NGRAMS), lowercase=False) \n",
    "last_name_vecs = vect.fit_transform(final_df.LastName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words = 1707\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for b in vocab:\n",
    "    c = vocab[b]\n",
    "    words.append((last_name_vecs[:, c].sum(), b))\n",
    "\n",
    "words = sorted(words, reverse=True)\n",
    "words_list = [w[1] for w in words]\n",
    "num_words = len(words_list)\n",
    "print(\"num_words = %d\" % num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ngrams(text, n):\n",
    "    a = zip(*[text[i:] for i in range(n)])\n",
    "    wi = []\n",
    "    for i in a:\n",
    "        w = ''.join(i)\n",
    "        try:\n",
    "            idx = words_list.index(w)\n",
    "        except:\n",
    "            idx = 0\n",
    "        wi.append(idx)\n",
    "    return wi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([324, 50, 41, 15, 11, 13]),\n",
       "       list([182, 3, 389, 126, 4, 18, 6]),\n",
       "       list([133, 39, 119, 129, 112, 4]), ...,\n",
       "       list([240, 21, 125, 259, 164, 151]), list([43, 338, 123, 13]),\n",
       "       list([394, 184, 54, 330, 7])], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(final_df.LastName.apply(lambda c: find_ngrams(c, NGRAMS)))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max feature len = 27, Avg. feature len = 5\n"
     ]
    }
   ],
   "source": [
    "# check max/avg feature\n",
    "X_len = []\n",
    "for x in X:\n",
    "    X_len.append(len(x))\n",
    "\n",
    "max_feature_len = max(X_len)\n",
    "avg_feature_len = int(np.mean(X_len))\n",
    "print(\"Max feature len = %d, Avg. feature len = %d\" % (max_feature_len, avg_feature_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 4, 4, 4], dtype=int8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(final_df.Race.astype('category').cat.codes)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test dataset\n",
    "X_train,  X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400000,), (400000,), (100000,), (100000,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000 train sequences\n",
      "100000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "X_train shape: (400000, 20)\n",
      "X_test shape: (100000, 20)\n",
      "5 classes\n"
     ]
    }
   ],
   "source": [
    "'''The dataset is actually too small for LSTM to be of any advantage\n",
    "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
    "Notes:\n",
    "\n",
    "- RNNs are tricky. Choice of batch size is important,\n",
    "choice of loss and optimizer is critical, etc.\n",
    "Some configurations won't converge.\n",
    "\n",
    "- LSTM loss decrease patterns during training can be quite different\n",
    "from what you see with CNNs/MLPs/etc.\n",
    "'''\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.models import load_model\n",
    "\n",
    "max_features = num_words # 20000\n",
    "feature_len = 20 # avg_feature_len # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=feature_len)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=feature_len)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "print(num_classes, 'classes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400000, 20), (400000,), (100000, 20), (100000,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 80000, 4: 80000, 1: 80000, 2: 80000, 3: 80000})\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(y_train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 80000, 4: 80000, 1: 80000, 2: 80000, 3: 80000})\n"
     ]
    }
   ],
   "source": [
    "# transform the dataset\n",
    "oversample = SMOTE()\n",
    "newX, newy = oversample.fit_resample(X_train, y_train)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(newy)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400000, 20), (400000,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newX.shape, newy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,  50, 171,  23],\n",
       "       [  0,   0,   0, ...,  60, 164,   4],\n",
       "       [  0,   0,   0, ...,  84,  48,  74],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  61,  17,   2],\n",
       "       [  0,   0,   0, ...,   2,  18,  13],\n",
       "       [  0,   0,   0, ..., 803, 877, 219]], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,  50, 171,  23],\n",
       "       [  0,   0,   0, ...,  60, 164,   4],\n",
       "       [  0,   0,   0, ...,  84,  48,  74],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  61,  17,   2],\n",
       "       [  0,   0,   0, ...,   2,  18,  13],\n",
       "       [  0,   0,   0, ..., 803, 877, 219]], dtype=int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
      "y_train shape: (400000, 5)\n",
      "y_test shape: (100000, 5)\n"
     ]
    }
   ],
   "source": [
    "print('Convert class vector to binary class matrix '\n",
    "      '(for use with categorical_crossentropy)')\n",
    "y_train_hot = keras.utils.to_categorical(newy, num_classes)\n",
    "y_test_hot = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train shape:', y_train_hot.shape)\n",
    "print('y_test shape:', y_test_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 32)            54624     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               82432     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 137,701\n",
      "Trainable params: 137,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, 32, input_length=feature_len))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE = 1000000\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/10\n",
      "11250/11250 - 211s - loss: 1.2606 - accuracy: 0.4783 - val_loss: 1.2142 - val_accuracy: 0.5042\n",
      "Epoch 2/10\n",
      "11250/11250 - 205s - loss: 1.2120 - accuracy: 0.5031 - val_loss: 1.1987 - val_accuracy: 0.5148\n",
      "Epoch 3/10\n",
      "11250/11250 - 210s - loss: 1.1923 - accuracy: 0.5140 - val_loss: 1.1811 - val_accuracy: 0.5207\n",
      "Epoch 4/10\n",
      "11250/11250 - 224s - loss: 1.1776 - accuracy: 0.5224 - val_loss: 1.1706 - val_accuracy: 0.5297\n",
      "Epoch 5/10\n",
      "11250/11250 - 223s - loss: 1.1663 - accuracy: 0.5288 - val_loss: 1.1633 - val_accuracy: 0.5345\n",
      "Epoch 6/10\n",
      "11250/11250 - 234s - loss: 1.1579 - accuracy: 0.5336 - val_loss: 1.1580 - val_accuracy: 0.5374\n",
      "Epoch 7/10\n",
      "11250/11250 - 244s - loss: 1.1508 - accuracy: 0.5368 - val_loss: 1.1565 - val_accuracy: 0.5360\n",
      "Epoch 8/10\n",
      "11250/11250 - 228s - loss: 1.1453 - accuracy: 0.5398 - val_loss: 1.1497 - val_accuracy: 0.5414\n",
      "Epoch 9/10\n",
      "11250/11250 - 214s - loss: 1.1416 - accuracy: 0.5423 - val_loss: 1.1486 - val_accuracy: 0.5437\n",
      "Epoch 10/10\n",
      "11250/11250 - 212s - loss: 1.1369 - accuracy: 0.5441 - val_loss: 1.1456 - val_accuracy: 0.5439\n",
      "3125/3125 - 11s - loss: 1.1521 - accuracy: 0.5397\n",
      "Test score: 1.1520525217056274\n",
      "Test accuracy: 0.5397499799728394\n"
     ]
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit(newX, y_train_hot, batch_size=batch_size, epochs=EPOCHS,\n",
    "          validation_split=0.1, verbose=2)\n",
    "score, acc = model.evaluate(X_test, y_test_hot,\n",
    "                            batch_size=batch_size, verbose=2)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 - 10s\n",
      "3125/3125 - 9s\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "Asian Or Pacific Islander       0.71      0.58      0.64     20000\n",
      "      Black, Not Hispanic       0.48      0.70      0.57     20000\n",
      "                 Hispanic       0.66      0.75      0.70     20000\n",
      "      White, Not Hispanic       0.44      0.59      0.50     20000\n",
      "                    Other       0.32      0.08      0.13     20000\n",
      "\n",
      "                 accuracy                           0.54    100000\n",
      "                macro avg       0.52      0.54      0.51    100000\n",
      "             weighted avg       0.52      0.54      0.51    100000\n",
      "\n",
      "[[11601  2086  2351  2831  1131]\n",
      " [  621 13942   412  4234   791]\n",
      " [  994  1075 15068  2199   664]\n",
      " [  620  5896   932 11808   744]\n",
      " [ 2595  5809  4166  5874  1556]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test, verbose=2)\n",
    "p = model.predict_proba(X_test, verbose=2) # to predict probability\n",
    "target_names = ['Asian Or Pacific Islander','Black, Not Hispanic','Hispanic','White, Not Hispanic','Other']\n",
    "print(classification_report(np.argmax(y_test_hot, axis=1), y_pred, target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(y_test_hot, axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/fl_voter_reg/lstm/fl_all_ln_lstm_5_cat.h5')\n",
    "words_df = pd.DataFrame(words_list, columns=['vocab'])\n",
    "words_df.to_csv('./models/fl_voter_reg/lstm/fl_all_ln_vocab_5_cat.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
